\subsection{34. Что такое канонические корреляции, сколько их}


Пусть у нас имеется два набора случайных величин:

\begin{align}
\eta =& \Tr{(\eta_1, …, \eta_q)}\\
\xi =& \Tr{(\xi_1, …, \xi_p)}
\end{align}

Не умаляя общности будем считать, что они центрированы. Тогда 
\begin{dfn}
Первой канонической корреляцией называется 
\begin{equation}
r_1^2 = \max \limits_{A, B} \rho^2(\Tr{A}\xi, \Tr{B}\eta),
\end{equation}
где $A \in \R^p, B \in \R^q$.
$i$-ой каноническая корреляция определяется аналогично с условием, что максимум берется по некоррелированным с предыдущими случайным величинам:
\begin{equation}
\label{cancordef}
r_i^2 = \max \limits_{\substack{A, B\\ \rho(A\xi, A_{j}\xi) = 0\\\rho(B\eta, B_{j}\eta) = 0 \\ 1 \leq j < i} } \rho^2(\Tr{A}\xi, \Tr{B}\eta)
\end{equation}

\end{dfn}
Канонических корреляций будет $s = \min(p, q)$.
\subsection{37. Канонические переменные, как находятся?}
{\color{blue} тут оригинальный порядок вопросов уплыл от порядка, в котором все удобно определять}
Смотрим на \eqref{cancordef}. У нас каждая каноническая корреляция определяется с помощью двух векторов — они определяют новый базис. 
Новые признаки $\tilde{\eta}_i = \Tr{B}_i \eta$ и $\tilde{\xi}_i = \Tr{A}_i\xi$ называются правыми и левыми каноническими переменными. Находятся, как обычно, с помощью лин. алгебры:
\begin{equation}
\rho^2(\Tr{A}\xi, \Tr{B}\eta) = \frac{(\Tr{A}\Sigma_{xy}B)^2}{\left(\Tr{A}\Sigma_{xx}A\right)\left(\Tr{B}\Sigma_{yy}B\right)}, \text{где}
\end{equation}

\begin{align}
\Sigma_{xx} &= E \xi \Tr{\xi}\\
\Sigma_{xy} &= E \xi \Tr{\eta} \\
\Sigma_{yy} &= E \eta \Tr{\eta}
\end{align}

Отсюда сразу получаем, что задачу максимизации из \eqref{cancordef} можно переформулировать как
 \begin{equation}
\label{cancorargmax}
(A, B) = \argmax \limits_{\substack{A, B\\ \Tr{A}\Sigma_{xx}A=1\\ \Tr{B}\Sigma_{yy}B = 1}} \Tr{A} \Sigma_{xy} B
 \end{equation}

Если требуется найти больше, чем одну каноническую корреляцию/переменную/etc, то вводим дополнительное ограничение
\begin{equation}
\rho(A_i\xi, A_j\xi) = 0 \Leftrightarrow \Tr{A_i}\Sigma_{xx}A_j = 0
\end{equation}
Для  $\eta$ аналогично.

Задача \eqref{cancorargmax} эквивалентна (является) обобщенным задачам на собственные числа:
\begin{align}
\Sigma_{xy}\Sigma_{yy}^{-1}\Sigma_{yx} A = r^2 \Sigma_{xx}A\\
\Sigma_{yx}\Sigma_{xx}^{-1}\Sigma_{xy} B = r^2 \Sigma_{yy}B
\end{align}

Собственные числа у обоих задач совпадают, соответствующие вектора задают выражения канонических переменных через оригинальные признаки. 

\subsection{40. Корреляции внутри множества канонических переменных, левых и правых}
Как и в предыдущих обозначениях, $A_i, B_j$ — линейные функции для выражения новых признаков. $1 \leq i, j \leq s = min(p, q)$. 
Факт без док-ва: 
$$ \Inner{A_i\xi}{B_j\eta} = 0 i \neq j$$


\subsection{36. Множественная корреляция как каноническая корреляция, если число признаков с одной стороны равно 1}

Как все помнят, множественный коэффициент корреляции случайной величины $\eta$ относительно $\xi=(\xi_1, …, \xi_p)$ определяется как 
\begin{equation}
R^2(\eta, \{\xi\}) = 1 - \frac{\min\limits_{\hat{\eta} \in\{a_0 + \sum a_i \xi_i\}} E\left(\eta-\hat{\eta}\right)^2}{D\eta}
\end{equation}

Не умаляя общности считаем, что $\eta$ и $\xi$ центрированы. Также предположим, что $E\eta^2=1$. Тогда в \eqref{cancorargmax} условие на $\eta$ автоматически выполнено и $B=1$. Далее
\begin{equation}
\begin{split}
\min\limits_{\hat{\eta} \in\{a_0 + \sum a_i \xi_i\}} E\left(\eta-\hat{\eta}\right)^2 = \min\limits_{\substack{\hat{\eta}\\ E\hat{\eta}^2 = 1\\ k \geq 0}}  E\left(\eta-k\hat{\eta}\right)^2 = \\
\min \left(1 - 2k\rho(\eta, \hat{\eta}) + k^2\right) = \min\left( \left(k-\rho(\eta, \hat{\eta})\right)^2 + 1 - \rho^2(\eta, \hat{\eta})\right) 
\end{split}
\end{equation}
Заметим, что нахождение минимума данного выражения тоже самое, что и нахождение максимума $\rho^2(\eta,\hat{\eta})$. Кроме того, видно, что $R^2$ равен максимуму $\rho^2$, а следовательно множественный коэффициент корреляции и каноническая корреляция (при одномерном $\eta$) совпадают. 

\subsection{35. Значимость корреляции между множествами признаков и значимость многомерной множеств. регрессии.}

В многомерной множественной регрессии все ясно. Пусть $\Xi, Y \in \R^{n  \times q}$, $X \in \R^{n \times p}$, $B \in \R^{p \times q}$.
\begin{equation}
Y = X B  + \Xi
\end{equation}

Тогда MSE оценка $B$:
\begin{align}
\hat{B} &=  (\Tr{X}X)^{-1}\Tr{X}Y \\
\hat{Y} &= X\hat{B}
\end{align}

Как и раньше считаем, что признаки центрированы\footnote{под признаками понимаем как элементы матрицы $X$, так и элементы матрицы $Y$}. Тогда проверка значимости аналогична MANOVA:
\begin{align}
E &= \Tr{(\hat{Y} - Y)}(\hat{Y} - Y) \\
H &= \Tr{\hat{Y}}\hat{Y} 
\end{align}

Проверяется гипотеза о том, что $B = 0$. Статистика критерия остается той же, что и была:
\begin{align}
\Lambda& = \frac{|E|}{|H|+|E|} \sim \Lambda_p(\nu_H, \nu_E), \text{ где}\\
\nu_H& = p\\
\nu_E& = n - \nu_H - 1
\end{align}

И как мы узнали до этого, $\Lambda$ вычисляется через собственные числа:
$$ \Lambda = \prod \limits_{i=1}^{s}\frac{1}{\lambda_i+1} $$


В каноническом анализе значимость проверяется аналогично. С помощью $\Lambda_{prime}$ можно проверять, сколько корреляций значимы. Для проверки требуется нормальность данных. 
{\color{blue} Кажется 39 должен быть частным случаем этого вопроса}

\subsection{39. Как найти число значимых корреляционных переменных}
Смотрим предыдущий (35) вопрос + вспоминаем проверку с $\Lambda_{prime}$ из LDA. 

\subsection{38. Интерпретация канонических переменных через стандартизованные канонические функции и через факторную структуру}

Определения такие же, как и в PCA:
\begin{dfn}
Пусть старые признаки  $\xi$ и $\eta$ стандартизованы, т.е. для $1 \leq i \leq p$ $E\xi_i = 0, E\xi_i^2=1$ и 
$1 \leq i \leq q$ $E\eta_i=0, E\eta_i^2=1$. Пусть для $1\leq i \leq s$ $A_i$ и $B_i$ — функции (т.е. вектора, т.к. у нас все линейно), выражающие новые признаки через старые. Тогда $A_i$, $B_i$ — стандартизованные канонические функции.
\end{dfn}

\begin{dfn}
Факторная структура — корреляции старых признаков с новыми.
\end{dfn}
Как считать факторную структуру:
\begin{multline}
\rho(\xi, \Tr{A}_i\xi) = E\xi\Tr{\xi}A_i = \Sigma_{\xi\xi}A_i
\end{multline} 

\begin{multline}
\rho(\xi, \Tr{B}_i\eta) = E\xi\Tr{\eta}B_i = \Sigma_{\xi\eta}B_i
\end{multline} 


\begin{multline}
\rho(\eta, \Tr{B}_i\eta) = E\eta\Tr{\eta}B_i = \Sigma_{\eta\eta}B_i
\end{multline} 

Интерпретация — аналогично PCA и регрессии. 



